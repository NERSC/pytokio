"""
Retrieve the contents of a GGIOSTAT database and cache it locally.
"""

import sys
import datetime
import argparse
import warnings
import tokio.debug
import tokio.timeseries
import tokio.connectors.ggiostatdb
import tokio.connectors.hdf5

DATE_FMT = "%Y-%m-%dT%H:%M:%S"
DATE_FMT_PRINT = "YYYY-MM-DDTHH:MM:SS"

SCHEMA_VERSION = "1"

class DatasetDict(dict):
    """A dictionary containing TimeSeries objects

    Contains the TimeSeries objects being populated from an GGIOSTAT database.
    Implemented as a class so that a single object can store all of the
    TimeSeries objects that are generated by multiple method calls.
    """
    def __init__(self, query_start, query_end, timestep, sort_hex=True, *args, **kwargs):
        super(DatasetDict, self).__init__(*args, **kwargs)
        self.query_start = query_start
        self.query_end = query_end
        self.timestep = timestep
        self.sort_hex = sort_hex

        self.config = {
            'datatargets/readbytes': {
                "units": "bytes",
                "delta": False,
                "column": "BYTES_READ",
            },
            'datatargets/writebytes': {
                "units": "bytes",
                "delta": False,
                "column": "BYTES_WRITTEN",
            },
            # XXX more?
        }

        # Initialize raw datasets - extend query by one extra timestep so we can calculate deltas
        self.schema = tokio.connectors.hdf5.SCHEMA.get(SCHEMA_VERSION)
        if self.schema is None:
            raise KeyError("Schema version %d is not known by connectors.hdf5" % SCHEMA_VERSION)

    def init_datasets(self, dataset_names, columns):
        """Populate empty datasets within self

        Creates and attachs TimeSeries objects to self based on a given column list

        Args:
            dataset_names (list of str): keys corresponding to self.config
                defining which datasets are being initialized
            columns (list of str): column names to use in the TimeSeries
                datasets being created
        """
        for dataset_name in dataset_names:
            hdf5_dataset_name = self.schema.get(dataset_name)
            if hdf5_dataset_name is None:
                warnings.warn("Skipping %s (not in schema)" % dataset_name)
            else:
                self[dataset_name] = tokio.timeseries.TimeSeries(dataset_name=hdf5_dataset_name,
                                                                 start=self.query_start,
                                                                 end=self.query_end,
                                                                 timestep=self.timestep,
                                                                 num_columns=len(columns),
                                                                 column_names=columns,
                                                                 sort_hex=self.sort_hex)

    def finalize(self):
        """Convert datasets to deltas where necessary and tack on metadata

        Perform a few finishing actions to all datasets contained in self after
        they have been populated.  Such actions are configured entirely in
        self.config and require no external input.
        """
        self.set_timeseries_metadata(list(self.config.keys()))

    def set_timeseries_metadata(self, dataset_names):
        """Set metadata constants (version, units, etc) on datasets and groups

        Args:
            dataset_names (list of str): keys corresponding to self.config for
                the datasets whose metadata should be set
        """
        for dataset_name in dataset_names:
            if dataset_name in self:
                self[dataset_name].dataset_metadata.update({
                    'version': SCHEMA_VERSION,
                    'units': self.config[dataset_name]['units']
                })
                self[dataset_name].group_metadata.update({'source': 'ggiostat'})

    def archive_fs_data(self, ggiostatdb):
        """Extract and encode data from GGIOSTAT's tables

        Queries the GGIOSTAT database, interprets resulting rows, and populates a
        dictionary of TimeSeries objects with those values.

        Args:
            ggiostatdb (GgiostatDb): database object
        """

        dataset_names = [
            'datatargets/readbytes',
            'datatargets/writebytes'
        ]

        self.init_datasets(dataset_names, ggiostatdb.node_names)

        # Now query the fs data to get byte counts over the query time range
        results, columns = ggiostatdb.get_fs_data(self.query_start, self.query_end)

        # Index the columns to speed up insertion of data
        col_map = {}
        try:
            for db_col in ['NODE_NAME', 'SECONDS', 'BYTES_READ',
                           'BYTES_WRITTEN', 'OPEN_COUNT', 'CLOSE_COUNT',
                           'READ_REQUESTS', 'WRITE_REQUESTS', 'READ_DIRECTORY']:
                col_map[db_col] = columns.index(db_col)
        except ValueError:
            raise ValueError("GGIOSTAT database schema does not match expectation")

        # Loop through all the results of the timeseries query
        for row in results:
            # GGIOSTAT timestamps are stored as seconds since epoch -- convert to datetime.datetime
            timestamp = datetime.datetime.fromtimestamp(row[col_map['SECONDS']])
            target_name = row[col_map['NODE_NAME']]
            for dataset_name in dataset_names:
                target_dbcol = self.config[dataset_name].get('column')
                if target_dbcol is not None:
                    # XXX LAMBDA
                    self[dataset_name].insert_element(
                        timestamp,
                        target_name,
                        row[col_map[target_dbcol]])
                else:
                    errmsg = "%s in self.config but missing 'column' setting" % dataset_name
                    raise KeyError(errmsg)

def init_hdf5_file(datasets, columns, init_start, init_end, hdf5_file):
    """
    Initialize the datasets at full dimensions in the HDF5 file if necessary
    """
    schema = tokio.connectors.hdf5.SCHEMA.get(SCHEMA_VERSION)
    for dataset_name, dataset in datasets.items():
        hdf5_dataset_name = schema.get(dataset_name)
        if hdf5_dataset_name is None:
            if '/_' not in dataset_name:
                warnings.warn("Dataset key %s is not in schema" % dataset_name)
            continue
        if hdf5_dataset_name not in hdf5_file:
            # attempt to convert dataset into a timeseries
            timeseries = hdf5_file.to_timeseries(dataset_name=hdf5_dataset_name)

            # if dataset -> timeseries failed, create and commit a new, empty timeseries
            if timeseries is None:
                timeseries = tokio.timeseries.TimeSeries(dataset_name=hdf5_dataset_name,
                                                         start=init_start,
                                                         end=init_end,
                                                         timestep=dataset.timestep,
                                                         num_columns=len(columns),
                                                         column_names=columns)
                hdf5_file.commit_timeseries(timeseries=timeseries)
            print("Initialized %s in %s with size %s" % (
                hdf5_dataset_name,
                hdf5_file.name,
                timeseries.dataset.shape))

def archive_ggiostatdb(ggiostatdb, init_start, init_end, timestep, output_file, query_start, query_end):
    """
    Given a start and end time, retrieve all of the relevant contents of an GGIOSTAT
    database.
    """
    datasets = DatasetDict(query_start, query_end, timestep)
    datasets.archive_fs_data(ggiostatdb)
    datasets.finalize()

    with tokio.connectors.hdf5.Hdf5(output_file) as hdf5_file:
        hdf5_file.attrs['version'] = SCHEMA_VERSION

        init_hdf5_file(datasets, ggiostatdb.node_names, init_start, init_end, hdf5_file)

        for dataset in datasets.values():
            print("Writing out %s" % dataset.dataset_name)
            hdf5_file.commit_timeseries(dataset)

    tokio.debug.debug_print("Wrote output to %s" % output_file)

def main(argv=None):
    """Entry point for the CLI interface
    """
    parser = argparse.ArgumentParser()
    parser.add_argument("-o", "--output", type=str, default='output.hdf5',
                        help="output file (default: output.hdf5)")
    parser.add_argument('--init-start', type=str, default=None,
                        help='first timestamp (inclusive) when creating new output file,' +
                        ' in %s format (default: same as start)' % DATE_FMT_PRINT)
    parser.add_argument('--init-end', type=str, default=None,
                        help='final timestamp (exclusive) when creating new output file,' +
                        ' in %s format (default: same as end)' % DATE_FMT_PRINT)
    parser.add_argument('--debug', action='store_true', help="produce debug messages")
    parser.add_argument('--timestep', type=int, default=5,
                        help='collection frequency, in seconds (default: 5)')
    parser.add_argument("--file_system", type=str, default=None, help="file system name")
    parser.add_argument("--database", type=str, default=None, help="database name")
    parser.add_argument("--user", type=str, default=None, help="database user")
    parser.add_argument("--password", type=str, default=None, help="database password")
    parser.add_argument("query_start", type=str, help="start time in %s format" % DATE_FMT_PRINT)
    parser.add_argument("query_end", type=str, help="end time in %s format" % DATE_FMT_PRINT)
    args = parser.parse_args(argv)

    if args.debug:
        tokio.debug.DEBUG = True

    # Convert CLI options into datetime
    try:
        query_start = datetime.datetime.strptime(args.query_start, DATE_FMT)
        query_end = datetime.datetime.strptime(args.query_end, DATE_FMT)
        init_start = query_start
        init_end = query_end
        if args.init_start:
            init_start = datetime.datetime.strptime(args.init_start, DATE_FMT)
        if args.init_end:
            init_end = datetime.datetime.strptime(args.init_end, DATE_FMT)
    except ValueError:
        sys.stderr.write("Start and end times must be in format %s\n" % DATE_FMT)
        raise

    # Basic input bounds checking
    if query_start >= query_end:
        raise Exception('query_start >= query_end')
    elif init_start >= init_end:
        raise Exception('query_start >= query_end')
    elif args.timestep < 1:
        raise Exception('--timestep must be > 0')

    ggiostatdb = tokio.connectors.ggiostatdb.GgiostatDb(
        file_system=args.file_system,
        dbname=args.database,
        dbuser=args.user,
        dbpassword=args.password)

    archive_ggiostatdb(ggiostatdb=ggiostatdb,
                       init_start=init_start,
                       init_end=init_end,
                       timestep=args.timestep,
                       output_file=args.output,
                       query_start=query_start,
                       query_end=query_end)
