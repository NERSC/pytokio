{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "import numpy\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.size'] = 16\n",
    "import matplotlib.pyplot\n",
    "import pandas\n",
    "\n",
    "import tokio\n",
    "import tokio.connectors.nersc_isdct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DATE = datetime.datetime(2016, 3, 11)\n",
    "\n",
    "date_start = TARGET_DATE\n",
    "date_end = TARGET_DATE + datetime.timedelta(days=1)\n",
    "\n",
    "print(\"Returning data from %s to %s\" % (date_start, date_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DailyTraffic(dict):\n",
    "    def __init__(self, date, use_caches=False, *args, **kwargs):\n",
    "        super(DailyTraffic, self).__init__(self, *args, **kwargs)\n",
    "        self.date = date\n",
    "        self.cache_file = None\n",
    "        if use_caches:\n",
    "            self.cache_file = 'dailytraffic_%s.json' % self.date.strftime(\"%Y-%m-%d\")\n",
    "            self.load_cache()\n",
    "\n",
    "    def __str__(self):\n",
    "        summaries_for_df = collections.defaultdict(dict)\n",
    "        ret = \"\"\n",
    "        for system, iovolumes in self.items():\n",
    "            ret += \"%12s %s read, %s written\\n\" % (\n",
    "                    system,\n",
    "                    tokio.common.humanize_bytes(iovolumes['read'], fmt=\"%6.1f %3s\"),\n",
    "                    tokio.common.humanize_bytes(iovolumes['write'], fmt=\"%6.1f %3s\"))\n",
    "        return ret\n",
    "    \n",
    "    def _store_rw_bytes(self, system, read, write):\n",
    "        added = {\n",
    "            'read': read,\n",
    "            'write': write,\n",
    "        }\n",
    "        self[system] = added\n",
    "        return added\n",
    "\n",
    "    def load_cache(self):\n",
    "        if self.cache_file and os.path.isfile(self.cache_file):\n",
    "            print(\"Loading cache from %s\" % self.cache_file)\n",
    "            self.update(json.load(open(self.cache_file, 'r')))\n",
    "\n",
    "    def save_cache(self):\n",
    "        if self.cache_file is not None and not os.path.isfile(self.cache_file):\n",
    "            json.dump(self, open(self.cache_file, 'w'))\n",
    "            print(\"Dumped to %s\" % self.cache_file)\n",
    "\n",
    "    def get_lustre(self, system):\n",
    "        if system in self:\n",
    "            return self.get(system)\n",
    "        \n",
    "        totals = {}\n",
    "        for rw in 'read', 'write':\n",
    "            tmp_df = tokio.tools.hdf5.get_dataframe_from_time_range(\n",
    "                fsname=system,\n",
    "                dataset_name='datatargets/%sbytes' % rw,\n",
    "                datetime_start=self.date,\n",
    "                datetime_end=(self.date + datetime.timedelta(days=1, seconds=-1)))\n",
    "            if tmp_df is not None:\n",
    "                totals[rw] = tmp_df.sum().sum()\n",
    "            else:\n",
    "                totals[rw] = -1.0\n",
    "\n",
    "        return self._store_rw_bytes(system, totals['read'], totals['write'])\n",
    "        \n",
    "    def get_isdct(self, system):\n",
    "        if system in self:\n",
    "            return self.get(system)\n",
    "\n",
    "        isdct_file = tokio.tools.common.enumerate_dated_files(\n",
    "            start=self.date,\n",
    "            end=(self.date + datetime.timedelta(days=1)),\n",
    "            template=tokio.config.CONFIG['isdct_files'])\n",
    "\n",
    "        zero_reads = 0\n",
    "        zero_writes = 0\n",
    "        read_tot = -1.0\n",
    "        write_tot = -1.0\n",
    "        if len(isdct_file) == 2:\n",
    "            yesterday_isdct = tokio.connectors.nersc_isdct.NerscIsdct(isdct_file[0])\n",
    "            today_isdct = tokio.connectors.nersc_isdct.NerscIsdct(isdct_file[-1])\n",
    "            isdct_diff = today_isdct.diff(yesterday_isdct)#, report_zeros=False)\n",
    "            for devicedata in isdct_diff['devices'].values():\n",
    "                if 'data_units_written_bytes' not in devicedata:\n",
    "                    zero_writes += 1\n",
    "                if 'data_units_read_bytes' not in devicedata:\n",
    "                    zero_reads += 1\n",
    "                read_tot += devicedata.get('data_units_read_bytes', 0.0)\n",
    "                write_tot += devicedata.get('data_units_written_bytes', 0.0)\n",
    "\n",
    "        return self._store_rw_bytes(system, read_tot, write_tot)\n",
    "\n",
    "    def get_hpss(self, system):\n",
    "        if system in self:\n",
    "            return self.get(system)\n",
    "        \n",
    "        hpss_file = tokio.tools.common.enumerate_dated_files(\n",
    "            start=self.date,\n",
    "            end=(self.date + datetime.timedelta(days=1, seconds=-1)),\n",
    "            template=tokio.config.CONFIG['hpss_report_files'])\n",
    "        if len(hpss_file) == 0:\n",
    "            return self._store_rw_bytes(system, read=-0.0, write=-0.0)\n",
    "        else:\n",
    "            assert len(hpss_file) == 1\n",
    "        hpss_dict = tokio.connectors.hpss.HpssDailyReport(hpss_file[0])\n",
    "        totals = hpss_dict[system]['io totals by client application']['total']\n",
    "\n",
    "        return self._store_rw_bytes(system, \n",
    "                             read=totals['read_gb'] * 2**30,\n",
    "                             write=totals['write_gb'] * 2**30)\n",
    "\n",
    "    def to_dataframe(self, *args, **kwargs):\n",
    "        default_kwargs = {\n",
    "            'orient': 'index'\n",
    "        }\n",
    "        default_kwargs.update(**kwargs)\n",
    "        return pandas.DataFrame.from_dict(self, *args, **default_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_traffic = DailyTraffic(TARGET_DATE, use_caches=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect data from storage systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lustre_fs in 'cscratch', 'scratch1', 'scratch2', 'scratch3', 'coribb':\n",
    "    io_traffic.get_lustre(lustre_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_traffic.get_isdct('coribb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_traffic.get_hpss('archive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(io_traffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_tibs = io_traffic.to_dataframe() / 2**40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = matplotlib.pyplot.subplots(figsize=(8,6))\n",
    "\n",
    "summary_tibs.T.plot(kind='bar', stacked=True, ax=ax, width=0.9)\n",
    "\n",
    "ax.yaxis.grid()\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_ylabel(\"Data Moved (TiB)\")\n",
    "ax.set_title(\"Storage Activity at NERSC on %s\" % TARGET_DATE.strftime(\"%b %d, %Y\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot multiple dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = io_traffic.to_dataframe(orient='columns')\n",
    "summary_df['date'] = TARGET_DATE\n",
    "summary_df['rw'] = summary_df.index.values\n",
    "summary_df.index = list(range(len(summary_df)))\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_START = datetime.datetime(2016, 1, 1)\n",
    "DATE_END = datetime.datetime.now()\n",
    "#DATE_END = DATE_START + datetime.timedelta(days=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = None\n",
    "now = DATE_START\n",
    "while now < DATE_END:\n",
    "    print(\"Processing %s\" % now)\n",
    "    io_traffic = DailyTraffic(now, use_caches=True)\n",
    "    \n",
    "    try:\n",
    "        for lustre_fs in 'cscratch', 'scratch1', 'scratch2', 'scratch3', 'coribb':\n",
    "            try:\n",
    "                io_traffic.get_lustre(lustre_fs)\n",
    "            except OSError:\n",
    "                pass\n",
    "    #   io_traffic.get_isdct('coribb') \n",
    "        io_traffic.get_hpss('archive')\n",
    "\n",
    "        now_df = io_traffic.to_dataframe(orient='columns')\n",
    "        now_df['date'] = now.date()\n",
    "        now_df['rw'] = now_df.index.values\n",
    "\n",
    "        if summary_df is not None:\n",
    "            summary_df = pandas.concat([summary_df, now_df])\n",
    "        else:\n",
    "            summary_df = now_df\n",
    "        io_traffic.save_cache()\n",
    "    except:\n",
    "        pass\n",
    "    now += datetime.timedelta(days=1)\n",
    "\n",
    "summary_df.index = list(range(len(summary_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_date = summary_df['date'] < datetime.datetime.now().date()\n",
    "\n",
    "plot_df = summary_df[summary_df['date'] < datetime.datetime.now().date()]\n",
    "\n",
    "data_cols = [x for x in list(summary_df.columns) if x != 'rw' and x != 'coribb' and x != 'date']\n",
    "\n",
    "plot_dfs = {\n",
    "     'read': plot_df[plot_df['rw'] == 'read'],\n",
    "     'write': plot_df[plot_df['rw'] == 'write'],\n",
    "}\n",
    "\n",
    "for key, plot_df in plot_dfs.items():\n",
    "    dt_index = pandas.DatetimeIndex(plot_df['date'])\n",
    "    plot_dfs[key].set_index(dt_index, inplace=True)\n",
    "    plot_dfs[key].replace(to_replace=-1.0, value=0.0, inplace=True)\n",
    "    plot_dfs[key].fillna(value=0.0, inplace=True)\n",
    "    \n",
    "    # optional - resample to a different time interval\n",
    "    plot_dfs[key] = plot_dfs[key].resample('M').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIT = 2**40\n",
    "UNIT_LABEL = \"TiB\"\n",
    "YTICKWIDTH = 256\n",
    "\n",
    "UNIT = 2**50\n",
    "UNIT_LABEL = \"PiB\"\n",
    "YTICKWIDTH = 10\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = matplotlib.pyplot.subplots(figsize=(12,8))\n",
    "\n",
    "x = next(iter(plot_dfs.values())).index.values\n",
    "y = {\n",
    "    'read': numpy.array([0.0 for y in range(len(x))]),\n",
    "    'write': numpy.array([0.0 for y in range(len(x))]),\n",
    "}\n",
    "\n",
    "ydirections = [\n",
    "    {\n",
    "        'y': 0.25,\n",
    "        's': '%s Written' % UNIT_LABEL,\n",
    "    },\n",
    "    {\n",
    "        'y': 0.75,\n",
    "        's': '%s Read' % UNIT_LABEL,\n",
    "    },\n",
    "]\n",
    "\n",
    "for rw, plot_df in plot_dfs.items():\n",
    "    for isys, system in enumerate(sorted(data_cols)):\n",
    "        this = y[rw] + plot_df[system].values / UNIT * (-1.0 if rw == 'write' else 1.0)\n",
    "        ax.fill_between(x, y[rw], this,\n",
    "                        label=\"%s\" % (system) if rw == 'read' else None,\n",
    "                        color='C%d' % (isys % len(plot_df.columns)),\n",
    "                       )\n",
    "        y[rw] = this\n",
    "\n",
    "# Make the y axis mirrored\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ymax = max(abs(ymin), ymax)\n",
    "ax.set_ylim(-ymax, ymax)\n",
    "\n",
    "# Draw the zero point\n",
    "ax.plot((xmin, xmax), (0, 0), ls='-', color='black')\n",
    "ax.set_xlim(min(x), max(x))\n",
    "\n",
    "# Make the tick marks more sensible\n",
    "ymax = int(min(ymax,max(ax.get_yticks())))\n",
    "new_yticks = [-1 * y for y in list(range(0, ymax + YTICKWIDTH, YTICKWIDTH))[::-1][:-1]] + list(range(0, ymax + YTICKWIDTH, YTICKWIDTH))\n",
    "ax.set_yticks(new_yticks)\n",
    "ax.set_yticklabels([abs(y) for y in new_yticks])\n",
    "ax.grid()\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "for kwargs in ydirections:\n",
    "    ax.text(x=-0.1,\n",
    "            ha='center',\n",
    "            va='center',\n",
    "            rotation=90,\n",
    "            transform=ax.transAxes,\n",
    "             **kwargs)\n",
    "\n",
    "ax.legend(ncol=2, loc='lower right') # 'upper right' if writes are greater than reads\n",
    "\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
