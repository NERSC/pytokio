{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAMI Demo\n",
    "\n",
    "This notebook demonstrates how to generate an UMAMI plot from a .csv file that has been generated by the `summarize_job.py` script included with pytokio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas\n",
    "import datetime\n",
    "import tokio.analysis.umami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We _must_ include `parse_dates` for the column which will be passed as each `UmamiMetric`'s timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv('sample_summary.csv.gz',\n",
    "                     parse_dates=['_datetime_start', '_datetime_end'],\n",
    "                     date_parser=lambda x: datetime.datetime.fromtimestamp(float(x))).set_index('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data\n",
    "\n",
    "We can select jobs that only match certain criteria by performing boolean operators on the DataFrame to generate filters.  We can then combine these filters using the `&` operator.\n",
    "\n",
    "In this example, we apply the following filters:\n",
    "\n",
    "1. Select only jobs that did more writes than reads.  The `darshan_biggest_{read,write}_api_bytes` keys contain the total number of bytes read or written by any single I/O API (POSIX or MPI-IO).\n",
    "\n",
    "2. Select only jobs that performed most of their I/O to the file system mounted at `/scratch2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select only jobs of a certain motif\n",
    "filtered_indices = [x.endswith('hacc_io_write') for x in df['darshan_app']]\n",
    "\n",
    "### Select only jobs that did more writes than reads (this is actually redundant since hacc_io_write only does writes)\n",
    "filtered_indices &= df['darshan_biggest_write_api_bytes'] > df['darshan_biggest_read_api_bytes']\n",
    "\n",
    "### Select jobs in a specific time range\n",
    "filtered_indices &= df['_datetime_start'] >= datetime.datetime(2017, 12, 7)\n",
    "filtered_indices &= df['_datetime_start'] < datetime.datetime(2017, 12, 21)\n",
    "\n",
    "### and also select only jobs whose I/O went to a file system mounted at a specific place.\n",
    "### Note that we have to check the type because Pandas will load empty CSV values as NaN,\n",
    "### which cannot be .startswith()ed.\n",
    "filtered_indices &= [ type(x) == str and x.startswith('/global/cscratch') for x in df['darshan_biggest_write_fs'] ]\n",
    "\n",
    "\n",
    "### Filter out dates where Darshan says we wrote more than Lustre thinks\n",
    "filtered_indices &= df['darshan_total_gibs_posix'] <= df['fs_tot_gibs_written']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now view a few example rows from our filtered data.  Note that we use `.T` to transpose the example rows just so you can see all of the metrics contained in this DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[filtered_indices].head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Umami object\n",
    "\n",
    "We want to look at the following metrics:\n",
    "\n",
    "1. `darshan_agg_perf_by_slowest_posix`, converted to GiB/s\n",
    "2. `darshan_total_gibs_posix` / ( `lmt_tot_gibs_read` + `lmt_tot_gibs_written` )\n",
    "3. `fshealth_ost_most_full_pct`\n",
    "4. `lmt_ave_mds_cpu`\n",
    "5. `lmt_max_oss_cpu`\n",
    "\n",
    "For each one, we create an `UmamiMetric` object, then we build the `Umami` object from them.  `UmamiMetric` objects can be given anything list-like (i.e., can be sliced in exactly one dimension), or `pandas.Series` objects.  In this example, we are passing it `pandas.Series` objects that are pulled straight out of our `df` DataFrame.\n",
    "\n",
    "Note that the following code is expanded out to make it easy to read; in practice, it's more concise to iteratively create and add new `UmamiMetric`s to the parent `Umami` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric1 = tokio.analysis.umami.UmamiMetric(\n",
    "    timestamps=df[filtered_indices]['_datetime_start'],\n",
    "    values=df[filtered_indices]['darshan_agg_perf_by_slowest_posix'] / 1024.0,\n",
    "    label=\"Performance (GiB/sec)\",\n",
    "    big_is_good=True)\n",
    "\n",
    "metric2 = tokio.analysis.umami.UmamiMetric(\n",
    "    timestamps=df[filtered_indices]['_datetime_start'],\n",
    "    values=df[filtered_indices]['darshan_total_gibs_posix'] /\n",
    "        (df[filtered_indices]['fs_tot_gibs_read'] + df[filtered_indices]['fs_tot_gibs_written']),\n",
    "    label=\"Coverage Factor (Bandwidth)\",\n",
    "    big_is_good=True)\n",
    "\n",
    "metric3 = tokio.analysis.umami.UmamiMetric(\n",
    "    timestamps=df[filtered_indices]['_datetime_start'],\n",
    "    values=df[filtered_indices]['fs_max_oss_cpu'],\n",
    "    label=\"Maximum OSS CPU Load (%)\",\n",
    "    big_is_good=False)\n",
    "\n",
    "metric4 = tokio.analysis.umami.UmamiMetric(\n",
    "    timestamps=df[filtered_indices]['_datetime_start'],\n",
    "    values=df[filtered_indices]['fs_ave_mds_cpu'],\n",
    "    label=\"Average MDS CPU Load (%)\",\n",
    "    big_is_good=False)\n",
    "\n",
    "metric5 = tokio.analysis.umami.UmamiMetric(\n",
    "    timestamps=df[filtered_indices]['_datetime_start'],\n",
    "    values=df[filtered_indices]['fs_tot_open_ops'] / 1.0e6,\n",
    "    label=\"Total open ops (MOps)\",\n",
    "    big_is_good=False)\n",
    "\n",
    "metric6 = tokio.analysis.umami.UmamiMetric(\n",
    "    timestamps=df[filtered_indices]['_datetime_start'],\n",
    "    values=df[filtered_indices]['fshealth_ost_most_full_pct'],\n",
    "    label=\"Most Full OST (% Used)\",\n",
    "    big_is_good=False)\n",
    "\n",
    "metric7 = tokio.analysis.umami.UmamiMetric(\n",
    "    timestamps=df[filtered_indices]['_datetime_start'],\n",
    "    values=df[filtered_indices]['topology_job_max_radius'],\n",
    "    label=\"Maximum Job Radius\",\n",
    "    big_is_good=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct an `Umami` object with the five metrics we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umami = tokio.analysis.umami.Umami()\n",
    "umami['performance'] = metric1\n",
    "umami['cf_bw'] = metric2\n",
    "umami['max_oss_cpu'] = metric3\n",
    "umami['ave_mds_cpu'] = metric4\n",
    "umami['tot_opens'] = metric5\n",
    "umami['fullest_ost'] = metric6\n",
    "umami['radius'] = metric7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the UMAMI\n",
    "\n",
    "The most obvious thing to do with an UMAMI is plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = umami.plot()\n",
    "axes[0].get_figure().savefig('umami.pdf', bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its data can also be presented as a DataFrame.  Note that the `UmamiMetric` metadata (the label and whether bigger values are better or not) are lost when we do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umami.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Umami` and `UmamiMetric` objects also serialize reasonably well.  The parent object can be converted either to a dictionary or a json string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print umami.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print umami.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
