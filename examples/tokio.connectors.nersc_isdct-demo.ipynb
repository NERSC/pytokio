{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IntelÂ® SSD Data Center Tool Connector\n",
    "\n",
    "This notebook demonstrates some of the quick analysis that can be done using the TOKIO connector for the Intel SSD Data Center Tool (ISDCT).  The format of the aggregated ISDCT outputs is specific to a tool developed at NERSC by David Paul and is therefore site-specific to NERSC, but the individual parsers for each ISDCT output file are generic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tokio.config\n",
    "import tokio.connectors.nersc_isdct\n",
    "import tokio.tools.common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DATE = datetime.datetime(year=2018, month=4, day=13)\n",
    "\n",
    "GENERATE_PLOTS = True\n",
    "PLOT_SUFFIX = \"png\" # or pdf, gif, jpeg..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Generating report for %s\" % TARGET_DATE.strftime('%c')\n",
    "isdct_file = tokio.tools.common.enumerate_dated_files(start=TARGET_DATE,\n",
    "                                                      end=TARGET_DATE,\n",
    "                                                      template=tokio.config.ISDCT_FILES)\n",
    "print \"Using input file: %s\" % isdct_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isdct_data = tokio.connectors.nersc_isdct.NerscIsdct(isdct_file[0])\n",
    "isdct_df = isdct_data.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Lifetime Read/Write Loads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following histograms demonstrate how many bytes have been written to and read from the SSD device _by applications_ over the entire service life of the SSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rw, column in ('read','data_units_read_bytes'), ('write', 'data_units_written_bytes'):\n",
    "    fig, ax = matplotlib.pyplot.subplots()\n",
    "    fig.set_size_inches(10, 6)\n",
    "    fig.suptitle(\"%s Volume Distribution\" % rw.title())\n",
    "\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.grid(True)\n",
    "    ax.set_xlabel(\"TiB %s\" % rw.title())\n",
    "    ax.set_ylabel(\"Number of SSDs\")\n",
    "    (isdct_df[column] / 2.0**40).hist(ax=ax, edgecolor='black')\n",
    "    \n",
    "    if GENERATE_PLOTS:\n",
    "        output_file = 'histogram_%s_%s_%s.%s' % (rw, column, TARGET_DATE.strftime(\"%Y-%m-%d\"), PLOT_SUFFIX)\n",
    "        fig.savefig(output_file, bbox_inches='tight')\n",
    "        print \"Saved figure to\", output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The read/write ratio from our applications should ideally match the read/write performance balance of the NVMe drives.  Writes are typically slower than reads on flash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = matplotlib.pyplot.subplots(figsize=(10, 6))\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(True)\n",
    "ax.set_xlabel(\"Read/Write Ratio\")\n",
    "ax.set_ylabel(\"Number of SSDs\")\n",
    "\n",
    "(isdct_df['data_units_read_bytes'] / isdct_df['data_units_written_bytes']).hist(ax=ax, edgecolor='black')\n",
    "\n",
    "if GENERATE_PLOTS:\n",
    "    output_file = 'histogram_readwrite_ratio.%s' % (PLOT_SUFFIX)\n",
    "    fig.savefig(output_file, bbox_inches='tight')\n",
    "    print \"Saved figure to\", output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Amplification Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write amplification factor (WAF) is the ratio of bytes written to the device _by applications_ to the bytes written to the physical NAND chips, which includes both application-generated writes as well as writes caused by garbage collection.\n",
    "\n",
    "A WAF of 1.0 is ideal; 2.0 is a normal level for the Intel SSDs we have in production.  High WAF is usually indicative of either\n",
    "\n",
    "1. very new SSDs which have not seen much application-generated I/O; in these cases, the constant background load of the NVMe controller bubbles up to the surface\n",
    "\n",
    "2. workloads which are very SSD-unfriendly.  These typically include writes that are not 4K aligned.  With DataWarp, the only non-4K aligned writes are those which are smaller than 4K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = matplotlib.pyplot.subplots()\n",
    "fig.set_size_inches(10, 6)\n",
    "fig.suptitle(\"WAF Distribution\")\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(True)\n",
    "ax.set_xlabel(\"Write Amplification Factor\")\n",
    "ax.set_ylabel(\"Number of SSDs\")\n",
    "isdct_df['write_amplification_factor'].hist(ax=ax, edgecolor='black')\n",
    "\n",
    "if GENERATE_PLOTS:\n",
    "    output_file = 'histogram_waf_%s.%s' % (TARGET_DATE.strftime(\"%Y-%m-%d\"), PLOT_SUFFIX)\n",
    "    fig.savefig(output_file, bbox_inches='tight')\n",
    "    print \"Saved figure to\", output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drive Writes per Day\n",
    "\n",
    "Our Intel P3608 SSDs have a warranty of 5.0 drive writes per day (DWPD) when provisioned at 1.6 TB capacity for the five-year service life of the drive.\n",
    "\n",
    "We have the option of reformatting the drives as 2.0 TB drives, which reduces the warranted endurance rating to 1.0 DWPD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = matplotlib.pyplot.subplots()\n",
    "fig.set_size_inches(10, 6)\n",
    "fig.suptitle(\"DWPD Distribution\")\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(True)\n",
    "ax.set_xlabel(\"Drive Writes per Day\")\n",
    "ax.set_ylabel(\"Number of SSDs\")\n",
    "drive_writes = isdct_df['data_units_written_bytes'] / isdct_df['physical_size']\n",
    "dwpd = drive_writes / isdct_df['power_on_hours'] * 24.0\n",
    "dwpd.hist(ax=ax, edgecolor='black')\n",
    "\n",
    "if GENERATE_PLOTS:\n",
    "    output_file = 'histogram_dwpd_%s.%s' % (TARGET_DATE.strftime(\"%Y-%m-%d\"), PLOT_SUFFIX)\n",
    "    fig.savefig(output_file, bbox_inches='tight')\n",
    "    print \"Saved figure to\", output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Scatter Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because many of the health metrics are ratios that get skewed when SSDs have seen very light use, it is sometimes helpful to correlate these health metrics with the number of hours the drives have been in service.\n",
    "\n",
    "We expect the total volume of I/O to each drive to increase over time, and the WAF should decrease over time as each drive reaches steady state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plots = [\n",
    "    ('power_on_hours', 'data_units_written_bytes'),\n",
    "    ('power_on_hours', 'data_units_read_bytes'),\n",
    "    ('power_on_hours', 'write_amplification_factor'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_and_fit_plot(df, x_key, y_key, fit=True):\n",
    "    fig, ax = matplotlib.pyplot.subplots()\n",
    "    fig.set_size_inches(10, 6)\n",
    "\n",
    "    x = df[x_key].values\n",
    "    y = df[y_key].values\n",
    "    ax.plot(x, y, 'o', alpha=0.5)\n",
    "\n",
    "    if fit:\n",
    "        ### attempt a linear fit to generate a visual aid\n",
    "        m, b = np.polyfit(x, y, 1)\n",
    "        ax.plot(x, m*x+b, \"-\")\n",
    "\n",
    "    ax.set_xlabel(x_key.replace('_', ' ').title())\n",
    "    ax.set_ylabel(y_key.replace('_', ' ').title())\n",
    "    plt.grid(True)\n",
    "    if GENERATE_PLOTS:\n",
    "        output_file = 'correlate_%s-%s_%s.%s' % (x_key, y_key, TARGET_DATE.strftime(\"%Y-%m-%d\"), PLOT_SUFFIX)\n",
    "        fig.savefig(output_file, bbox_inches='tight')\n",
    "        print \"Saved figure to\", output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x_key, y_key) in scatter_plots:\n",
    "    scatter_and_fit_plot(isdct_df, x_key, y_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify faulty node power sources\n",
    "\n",
    "The \"PLI Lock Loss\" counter was originally thought to be an indicator of unhealthy drives.  It turns out that this metric is really a PLL (phase-locked loop) lock loss count, which increments when the PCIe timing signal falls irreparably out of sync with the internal clock on the SSD.  This is __not__ an indicator of bad drive health as originally thought; it is an indicator of unclean power to the host node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pli_lock_losses = isdct_df[isdct_df['smart_pli_lock_loss_count_raw'] > 0]\n",
    "pli_lock_losses[['node_name', 'smart_pli_lock_loss_count_raw', 'power_on_hours']]\\\n",
    "    .sort_values('smart_pli_lock_loss_count_raw', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_key = 'power_on_hours'\n",
    "y_key = 'smart_pli_lock_loss_count_raw'\n",
    "fig, ax = matplotlib.pyplot.subplots()\n",
    "fig.set_size_inches(10, 6)\n",
    "\n",
    "ax.plot(isdct_df[x_key].values,\n",
    "        isdct_df[y_key].values,\n",
    "        marker='o',\n",
    "        linestyle='none',\n",
    "        alpha=0.5,\n",
    "        label=\"All SSDs\")\n",
    "ax.plot(pli_lock_losses[x_key],\n",
    "        pli_lock_losses[y_key],\n",
    "        marker='o',\n",
    "        linestyle='none',\n",
    "        alpha=0.5,\n",
    "        color='red',\n",
    "        markersize=10,\n",
    "        markerfacecolor='none',\n",
    "        label=\"Nonzero PLI Lock Loss\")\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(x_key.replace('_', ' ').title())\n",
    "ax.set_ylabel(y_key.replace('_', ' ').title())\n",
    "plt.grid(True)\n",
    "\n",
    "if GENERATE_PLOTS:\n",
    "    output_file = 'lockloss_vs_poweron_%s.%s' % (TARGET_DATE.strftime(\"%Y-%m-%d\"), PLOT_SUFFIX)\n",
    "    fig.savefig(output_file, bbox_inches='tight')\n",
    "    print \"Saved figure to\", output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
